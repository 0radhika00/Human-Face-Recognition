{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8238278,"sourceType":"datasetVersion","datasetId":4886713},{"sourceId":8349153,"sourceType":"datasetVersion","datasetId":4960219},{"sourceId":8365195,"sourceType":"datasetVersion","datasetId":4972270},{"sourceId":40051,"sourceType":"modelInstanceVersion","modelInstanceId":33730},{"sourceId":40106,"sourceType":"modelInstanceVersion","modelInstanceId":33780}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-07T13:23:30.958410Z","iopub.execute_input":"2024-05-07T13:23:30.958821Z","iopub.status.idle":"2024-05-07T13:23:30.976230Z","shell.execute_reply.started":"2024-05-07T13:23:30.958791Z","shell.execute_reply":"2024-05-07T13:23:30.974764Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"/kaggle/input/tacherfaces/tatcherFaces.mat\n/kaggle/input/resnet50/other/2/1/imagenet-vgg-verydeep-16.mat\n/kaggle/input/resnet50/other/1/1/imagenet-resnet-50-dag.mat\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **SIMPLEN_TIDY**","metadata":{}},{"cell_type":"code","source":"# import numpy as np\n\n\n# def vl_simplenn_tidy(net):\n#     tnet = {'layers': [], 'meta': {}}\n\n#     # copy meta information in net.meta subfield\n#     if 'meta' in net:\n#         tnet['meta'] = net['meta']\n\n#     if 'classes' in net:\n#         tnet['meta']['classes'] = net['classes']\n\n#     if 'normalization' in net:\n#         tnet['meta']['normalization'] = net['normalization']\n\n#     # Adjust for the new version of vl_imreadjpeg\n#     if isinstance(tnet, dict) and 'meta' in tnet:\n#         meta = tnet['meta']\n#         if isinstance(meta, dict) and 'normalization' in meta:\n#             normalization = meta['normalization']\n#             if isinstance(normalization, dict):\n#                 if 'cropSize' not in normalization and \\\n#                         'border' in normalization and \\\n#                         'imageSize' in normalization:\n#                     insz = normalization['imageSize'][:2]\n#                     bigimSz = insz + normalization['border']\n#                     normalization['cropSize'] = [x / bigimSz for x in insz]\n\n#     # copy layers\n#     # copy layers\n#     for l, layer in enumerate(net['layers']):\n#         defaults = {'name': f'layer{l}', 'precious': False}\n\n#         # Ignore custom layers (e.g., for classes the `in` operator does not work)\n#         # The only interface requirement for custom layers is forward and\n#         # backward function.\n#         if isinstance(layer, dict):  # Check if layer is a dictionary\n#             # Ignore custom layers (e.g., for classes the `in` operator does not work)\n#             # The only interface requirement for custom layers is forward and\n#             # backward function.\n#             if 'type' in layer and layer['type'] in {'conv', 'convt', 'bnorm'}:\n#                 if 'weights' not in layer:\n#                     layer['weights'] = [layer['filters'], layer['biases']]\n#                     del layer['filters']\n#                     del layer['biases']\n#             if 'weights' not in layer:\n#                 layer['weights'] = []\n\n#             # Check that weights include moments in batch normalization.\n#             if 'type' in layer and layer['type'] == 'bnorm':\n#                 if len(layer['weights']) < 3:\n#                     layer['weights'].append(np.zeros((layer['weights'][0].shape[0], 2), dtype=np.float32))\n\n#             # Fill in missing values.\n#             defaults_map = {\n#                 'conv': {'pad': 0, 'stride': 1, 'dilate': 1, 'opts': {}},\n#                 'pool': {'pad': 0, 'stride': 1, 'opts': {}},\n#                 'convt': {'crop': 0, 'upsample': 1, 'numGroups': 1, 'opts': {}},\n#                 'relu': {'leak': 0},\n#                 'dropout': {'rate': 0.5},\n#                 'normalize': {'param': [5, 1, 0.0001 / 5, 0.75]},\n#                 'lrn': {'param': [5, 1, 0.0001 / 5, 0.75]},\n#                 'pdist': {'noRoot': False, 'aggregate': False, 'p': 2, 'epsilon': 1e-3, 'instanceWeights': []},\n#                 'bnorm': {'epsilon': 1e-5}\n#             }\n#             if 'type' in layer and layer['type'] in defaults_map:\n#                 defaults = defaults_map[layer['type']]\n#             for key, value in defaults.items():\n#                 if key not in layer:\n#                     layer[key] = value\n\n#             # save back\n#             tnet['layers'].append(layer)\n\n#         return tnet\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-07T13:23:32.380277Z","iopub.execute_input":"2024-05-07T13:23:32.381133Z","iopub.status.idle":"2024-05-07T13:23:32.391467Z","shell.execute_reply.started":"2024-05-07T13:23:32.381085Z","shell.execute_reply":"2024-05-07T13:23:32.389943Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"# **VL_SIMPLENN**","metadata":{}},{"cell_type":"code","source":"# import numpy as np\n# import torch\n\n\n# def vl_simplenn(net, x, dzdy=None, res=None, **kwargs):\n#     opts = {\n#         'conserveMemory': False,\n#         'sync': False,\n#         'mode': 'normal',\n#         'accumulate': False,\n#         'cudnn': True,\n#         'backPropDepth': float('inf'),\n#         'skipForward': False,\n#         'parameterServer': None,\n#         'holdOn': False\n#     }\n#     layers = net['layers']\n#     print(layers,'*****')\n#     for k, v in kwargs.items():\n#         if k in opts:\n#             opts[k] = v\n            \n#     for layer in net['layers']:\n#         if layer['type'] == 'conv':\n#             print('Con')\n# #             x = torch.nn.functional.conv2d(res[-1], layer['weights'][0], layer['weights'][1],\n# #                                            padding=layer['pad'], stride=layer['stride'], dilation=layer['dilate'])\n#         elif layer['type'] == 'pool':\n#             print('Pool')\n# #             x = torch.nn.functional.max_pool2d(res[-1], layer['pool'], padding=layer['pad'],\n# #                                                stride=layer['stride'])\n#         elif layer['type'] == 'relu':\n#             print('RELU')\n# #             x = torch.nn.functional.relu(res[-1])\n\n# #         res.append(x)\n#     n = len(net['layers'])\n# #     print(n,'Number of layers')\n\n#     if dzdy is None:\n#         doder = False\n#         if opts['skipForward']:\n#             raise ValueError('RES structure must be provided for `skipForward`.')\n#     else:\n#         doder = True\n\n#     if opts['cudnn']:\n#         cudnn = {'CuDNN'}\n#         bnormCudnn = {'NoCuDNN'}\n#     else:\n#         cudnn = {'NoCuDNN'}\n#         bnormCudnn = {'NoCuDNN'}\n\n#     if opts['mode'] == 'normal':\n#         testMode = False\n#     elif opts['mode'] == 'test':\n#         testMode = True\n#     else:\n#         raise ValueError('Unknown mode \\'{}\\'.'.format(opts['mode']))\n\n#     gpuMode = isinstance(x, torch.Tensor)\n\n#     if res is None and not opts['skipForward']:\n#         res = [None] * (n + 1)\n#         res[0] = {'x': x}\n\n#     for i in range(n):\n#         if opts['skipForward']:\n#             break\n#         print('Layer creation')\n#         l = net['layers'][i]\n#         res[i]['time'] = torch.cuda.Event(enable_timing=True)\n#         res[i]['time'].record()\n#         print('CONV')\n#         if l['type'] == 'conv':\n#             res[i + 1]['x'] = torch.nn.functional.conv2d(res[i]['x'], l['weights'][0], l['weights'][1],\n#                                                          padding=l['pad'], stride=l['stride'], dilation=l['dilate'])\n\n#         elif l['type'] == 'pool':\n#             res[i + 1]['x'] = torch.nn.functional.max_pool2d(res[i]['x'], l['pool'], padding=l['pad'],\n#                                                              stride=l['stride'])\n\n#         elif l['type'] == 'relu':\n#             res[i + 1]['x'] = torch.nn.functional.relu(res[i]['x'], inplace=False)\n\n#         # Add more layer types as needed\n\n#         # Optionally forget intermediate results\n#         needsBProp = doder and i >= max(n - opts['backPropDepth'] + 1, 1)\n#         forget = opts['conserveMemory'] and not needsBProp\n\n#         if i > 0:\n#             lp = net['layers'][i - 1]\n#             forget = forget and (not needsBProp or (l['type'] == 'relu' and not lp['precious']))\n#             forget = forget and (l['type'] != 'loss' and l['type'] != 'softmaxloss') and not lp['precious']\n\n#         if forget:\n#             res[i]['x'] = None\n\n#         if gpuMode and opts['sync']:\n#             torch.cuda.synchronize()\n\n#         res[i]['time'].synchronize()\n#         res[i]['time'] = res[i]['time'].elapsed_time()\n\n#     if doder:\n#         pass  # Implement backward pass here\n\n#     return res\n","metadata":{"execution":{"iopub.status.busy":"2024-05-07T13:23:32.814899Z","iopub.execute_input":"2024-05-07T13:23:32.815368Z","iopub.status.idle":"2024-05-07T13:23:32.825982Z","shell.execute_reply.started":"2024-05-07T13:23:32.815333Z","shell.execute_reply":"2024-05-07T13:23:32.824270Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"# **EXTRACT FEATURES**","metadata":{}},{"cell_type":"code","source":"# import numpy as np\n# import torch\n# from PIL import Image\n# import scipy.io as sio\n\n\n# def extract_features(stim, typ, dagg_flag):\n# #     exec(open(run_path).read())\n# #     dagg_flag=0\n#     if dagg_flag == 0:\n# #         typ = typ.split(\"/\")[-1]\n#         net_data = sio.loadmat(typ)\n# #         key=net_data.keys()\n# #         print(,'***********************************************************************')\n#         net = vl_simplenn_tidy(net_data)\n    \n#         print(net['layers'],'****************************************************************************')\n#         nimages = len(stim)\n#         print(stim)\n#         # print(f\"nimages is {nimages}\")\n#         features = []\n# #         Src = net['meta'][0][0]['normalization'][0][0]['imageSize'][0]\n# #         rgb_values = net['meta'][0][0]['normalization'][0][0]['averageImage'][0][0]\n# #         print(rgb_values)\n# #         average_image = np.ones((Src[0], Src[1], 3))\n# #         print(average_image.shape)\n#         # print(stim[0][2][3].shape, \" is the shape\")\n# #         for ind in range(3):\n# #             average_image[:, :, ind] = rgb_values[ind]\n#         for i in range(nimages):\n#             img_pixel = stim[i][0]\n# #             print(img_pixel.shape, \" img\")\n#             # for j in range(4):\n\n#                 # Reshape the flat array to the desired shape, if needed\n#                 # reshape_stim = flat_stim.reshape((desired_shape))\n\n#                 # Convert to a NumPy array\n#             bimage_ip = np.array(img_pixel)\n# #             print(bimage_ip.shape)\n#             if len(bimage_ip.shape) < 3 or bimage_ip.shape[2] == 1:\n#                 bimage_ip = np.repeat(bimage_ip[:, :, np.newaxis], repeats=3, axis=2)\n# #             print(bimage_ip.shape)\n#             cimage = np.array(Image.fromarray(bimage_ip).resize((Src[1], Src[0])))\n#             cimage = cimage - average_image\n#             cimage = torch.tensor(cimage.transpose(2, 0, 1)).float()\n#             feature = vl_simplenn(net, cimage)\n# #             print(len(feature),'Feature Shape')\n#             features.append(feature)\n# #             print(feature,'features***************************************')\n#         return features\n\n#     elif dagg_flag == 1:\n# #         typ = typ.split(\"/\")[-1]\n#         net = sio.loadmat(typ)\n#         net['mode'] = 'test'\n#         print(net.keys())\n#         nimages = len(stim)\n#         Src = net['meta'][0][0]['normalization'][0][0]['imageSize'][0]\n#         features = []\n#         net['conserveMemory'] = False\n#         nL = len(net['layers']) - 1\n#         for i in range(nimages):\n#             img_pixel = stim[i][0]\n#             bimage_ip = np.array(img_pixel)\n#             print(\"success\")\n#             cimage = np.array(Image.fromarray(bimage_ip).resize((Src[1], Src[0])))\n#             print(\"success2\")\n#             print(cimage.shape,'cimage shape')\n#             temp=net['meta'][0][0]['normalization'][0][0]['averageImage'][0][0]\n#             print(temp.shape,'temp shape')\n#             cimage = cimage - temp\n#             cimage = torch.tensor(cimage.transpose(2, 0, 1)).float()\n#             print(net)\n#             net.eval({'data': cimage})\n#             scores = []\n#             for L in range(nL):\n#                 scores.append(net.vars[L].value.view(-1).numpy())\n#             features.append(scores)\n#         return features","metadata":{"execution":{"iopub.status.busy":"2024-05-07T13:23:33.124573Z","iopub.execute_input":"2024-05-07T13:23:33.124980Z","iopub.status.idle":"2024-05-07T13:23:33.134035Z","shell.execute_reply.started":"2024-05-07T13:23:33.124947Z","shell.execute_reply":"2024-05-07T13:23:33.132812Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"# **LAYERWISE_NON_VGG**","metadata":{}},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# import numpy as np\n\n\n# def layerwise_mi_nonVGGfigures(mean_data, sem_data, file_name, reference_mi=None, reference_name=None, legend_name=None,\n#                                y_label=None, shaded_region_name='Human Perception', y_limits=(-1, 1)):\n#     if y_label is None:\n#         y_label = 'XXX'\n\n#     if reference_mi is not None:\n#         if isinstance(reference_mi, (int, float)):\n#             reference_mi = [reference_mi]\n#         if isinstance(reference_name, str):\n#             reference_name = [reference_name]\n\n#     fig, ax = plt.subplots(figsize=(6.4, 4))\n\n#     # Drawing the human perception rectangle\n#     rect_color = (0.8, 0.8, 0.8)\n#     rect = plt.Rectangle((1, y_limits[0]), len(mean_data[0]), y_limits[1] - y_limits[0], facecolor=rect_color,\n#                          edgecolor='none')\n#     ax.add_patch(rect)\n\n#     # Plotting the data\n#     line_colors = plt.cm.get_cmap('tab10', len(mean_data))\n#     marker_size = 1\n#     layer_ind = np.arange(1, len(mean_data[0]) + 1)\n\n#     for ind, data in enumerate(mean_data):\n#         if sem_data is not None:\n#             plt.errorbar(layer_ind, data, yerr=sem_data[ind], fmt='o-', color=line_colors(ind),\n#                          markerfacecolor=line_colors(ind), linewidth=0.5, markersize=marker_size, capsize=3)\n#         else:\n#             plt.plot(layer_ind, data, 'o-', color=line_colors(ind), markerfacecolor=line_colors(ind), linewidth=0.5,\n#                      markersize=marker_size)\n\n#     # Visual search modulation index\n#     if reference_mi is not None:\n#         for i, mi in enumerate(reference_mi):\n#             ax.axhline(y=mi, linestyle='--', color='black', linewidth=0.5)\n#             if reference_name is not None:\n#                 ax.text(2, mi + 0.1, reference_name[i], fontsize=6)\n\n#     # Naming the shaded region\n#     ax.text(3, 0.9, shaded_region_name, fontsize=6)\n\n#     # Correcting the plot\n#     ax.set_xlim(1, len(mean_data[0]))\n#     ax.set_ylim(y_limits)\n#     ax.set_xticks([1, len(mean_data[0])])\n#     ax.set_xticklabels([1, len(mean_data[0])])\n#     ax.set_yticks([y_limits[0], 0, y_limits[1]])\n#     ax.set_yticklabels([y_limits[0], 0, y_limits[1]])\n#     ax.set_xlabel('VGG-16, layers')\n#     ax.set_ylabel(y_label)\n\n#     # Legends\n#     if legend_name is not None:\n#         ax.legend(legend_name, fontsize=6, loc='best', frameon=False)\n\n#     plt.tight_layout()\n#     plt.savefig(file_name + '.pdf')\n#     plt.close()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-07T13:23:33.431781Z","iopub.execute_input":"2024-05-07T13:23:33.432544Z","iopub.status.idle":"2024-05-07T13:23:33.439863Z","shell.execute_reply.started":"2024-05-07T13:23:33.432507Z","shell.execute_reply":"2024-05-07T13:23:33.438488Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"# **NEW_VL_SIMPLENN**","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nimport torch.nn as nn\n\ndef vl_simplenn(net, x, res=None):\n\n#     print(x)\n    n=len(net.features) + len(net.classifier)\n#     print(\"LEn:\",n)\n    if (res is None):\n        res = [{'x': None} for _ in range(n + 1)]\n\n    res[0]['x'] = x\n    i=0\n    for (name, layer) in net.named_children():\n        \n        for  (sub_name, sub_layer) in (layer.named_children()):\n#             print(\"Iteration:\",i)\n#             print(sub_layer)\n            ltype=sub_layer.__class__.__name__\n#             print(f\"  Type: {sub_layer.__class__.__name__}\")\n\n\n\n\n\n    # res[i]['time'] = time.time()\n            if ltype == 'Conv2d':\n#                 print(res[i]['x'].shape,sub_layer.weight.shape,sub_layer.bias.shape)\n                res[i + 1]['x'] = F.conv2d(res[i]['x'], sub_layer.weight,sub_layer.bias,\n                            padding=sub_layer.padding, stride=sub_layer.stride, dilation=sub_layer.dilation)\n\n            elif ltype == 'MaxPool2d':\n                res[i + 1]['x'] = F.max_pool2d(res[i]['x'],\n                            padding=sub_layer.padding, stride=sub_layer.stride,kernel_size=sub_layer.kernel_size)\n            elif ltype=='Linear':\n                linear_layer = nn.Linear(res[i]['x'].flatten().shape[0], 4096)\n                output_tensor = linear_layer(res[i]['x'].flatten())\n                res[i + 1]['x'] = output_tensor.to(torch.float32)\n#                 temp= nn.Linear(res[i]['x'].flatten().shape[0], 4096)\n#                 res[i + 1]['x'] = torch.tensor(temp),dtype=torch.float32\n            elif ltype=='Dropout':\n                i=i-1\n#                 dropout_layer = CustomDropout(p=0.5)\n#                 print(dropout_layer)\n#                 res[i + 1]['x'] = dropout_layer\n            elif ltype== 'ReLU':\n                # if l['leak'] > 0:\n                #     leak = {'leak': l['leak']}\n                # else:\n                leak = {}\n\n                if res[i]['x'] is not None:\n                    res[i + 1]['x'] = F.relu(res[i]['x'], **leak)\n                else:\n                    res[i + 1]['x'] = F.relu(res[i + 1]['x'], **leak)\n            i+=1\n\n\n\n    return res\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T21:29:31.161370Z","iopub.execute_input":"2024-05-09T21:29:31.161786Z","iopub.status.idle":"2024-05-09T21:29:31.177614Z","shell.execute_reply.started":"2024-05-09T21:29:31.161756Z","shell.execute_reply":"2024-05-09T21:29:31.176332Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# **NEW_EXTRACT_FEATURE**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nnl=37\nthatcherIndex1 = np.zeros((20, nl))","metadata":{"execution":{"iopub.status.busy":"2024-05-09T21:29:33.214066Z","iopub.execute_input":"2024-05-09T21:29:33.214498Z","iopub.status.idle":"2024-05-09T21:29:33.219702Z","shell.execute_reply.started":"2024-05-09T21:29:33.214466Z","shell.execute_reply":"2024-05-09T21:29:33.218475Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nnl=37\nthatcherIndex2 = np.zeros((20, nl))","metadata":{"execution":{"iopub.status.busy":"2024-05-09T21:29:33.835682Z","iopub.execute_input":"2024-05-09T21:29:33.836084Z","iopub.status.idle":"2024-05-09T21:29:33.841946Z","shell.execute_reply.started":"2024-05-09T21:29:33.836052Z","shell.execute_reply":"2024-05-09T21:29:33.840715Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# **CHECK THACHER EFFECT**","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\ndef CheckThatcherEffect(features,i):\n\n    for L in range(nl-1):\n        v1 = features[0][L]['x']  # Access feature data for image ind, layer 1\n        v2 = features[1][L]['x']  # Access feature data for image ind, layer 2\n        v3 = features[2][L]['x']  # Access feature data for image ind, layer 3\n        v4 = features[3][L]['x']  # Access feature data for image ind, layer 4\n#         print('v1:',v1)\n        # Calculate Euclidean norms\n        v12 = np.linalg.norm(v1.detach().numpy() - v2.detach().numpy())\n        v34 = np.linalg.norm(v3.detach().numpy() - v4.detach().numpy())\n\n        thatcherIndex1[i, L] = (v12 - v34) / (v12 + v34)\n\n#     return thatcherIndex\n\n# Example usage:\n# Assuming features is a list of dictionaries/tensors for each image and each layer\n# features = [img1_layer1, img1_layer2, img2_layer1, img2_layer2, ...]\n# where each img*_layer* is a dictionary/tensor containing 'x' key for feature map\n\n# thatcherIndex = CheckThatcherEffect(features)\n# print(thatcherIndex)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T21:29:34.609669Z","iopub.execute_input":"2024-05-09T21:29:34.610077Z","iopub.status.idle":"2024-05-09T21:29:34.619253Z","shell.execute_reply.started":"2024-05-09T21:29:34.610044Z","shell.execute_reply":"2024-05-09T21:29:34.618073Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\ndef CheckThatcherEffect(features,i):\n\n    for L in range(nl-1):\n        v1 = features[0][L]['x']  # Access feature data for image ind, layer 1\n        v2 = features[1][L]['x']  # Access feature data for image ind, layer 2\n        v3 = features[2][L]['x']  # Access feature data for image ind, layer 3\n        v4 = features[3][L]['x']  # Access feature data for image ind, layer 4\n#         print('v1:',v1)\n        # Calculate Euclidean norms\n        v12 = np.linalg.norm(v1.detach().numpy() - v2.detach().numpy())\n        v34 = np.linalg.norm(v3.detach().numpy() - v4.detach().numpy())\n\n        thatcherIndex2[i, L] = (v12 - v34) / (v12 + v34)\n\n#     return thatcherIndex\n\n# Example usage:\n# Assuming features is a list of dictionaries/tensors for each image and each layer\n# features = [img1_layer1, img1_layer2, img2_layer1, img2_layer2, ...]\n# where each img*_layer* is a dictionary/tensor containing 'x' key for feature map\n\n# thatcherIndex = CheckThatcherEffect(features)\n# print(thatcherIndex)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T21:29:25.514259Z","iopub.execute_input":"2024-05-09T21:29:25.514713Z","iopub.status.idle":"2024-05-09T21:29:25.524261Z","shell.execute_reply.started":"2024-05-09T21:29:25.514679Z","shell.execute_reply":"2024-05-09T21:29:25.523069Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torchvision.transforms as transforms\nfrom torchvision.models import vgg16\nfrom PIL import Image\nimport numpy as np\n\ndef extract_features(stim_data, types, dagg_flag):\n    # Load the VGG16 model\n    model1 = vgg16(pretrained=True)\n    model1.eval()  # Set the model to evaluation mode\n    model2=vgg16(pretrained=False)\n    model2.eval()\n    # Define the preprocessing transformations\n    preprocess = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n\n    # Extract the image data from the loaded dictionary\n    # stim_images = stim_data['stim'][0]\n#     print(stim_data['stim'])\n\n    nimages =  len(stim_data)\n    if dagg_flag==0:\n        features1=  []\n        features2=[]\n        i=0\n        for ind in range(nimages):\n            print(\"Image:\",ind)\n            # Convert the numpy array to PIL Image\n            image_array = stim_data[ind][0]\n            if len(image_array.shape) < 3:\n                image_array = np.stack((image_array,) * 3, axis=-1)\n            image = Image.fromarray(image_array)\n\n        # Preprocess and normalize the image\n            image_tensor = preprocess(image).unsqueeze(0)\n                # Perform inference using the model\n#             with torch.no_grad():\n#                 output = model(image_tensor)\n\n           # Append the features to the list\n            features1.append(vl_simplenn(model1, image_tensor))\n            features2.append(vl_simplenn(model2, image_tensor))\n            if ind%4==3:\n                print('Calculating CheckThatcherEffect of 4 images')\n                CheckThatcherEffect(features1,i)\n                CheckThatcherEffect(features2,i)\n                i=i+1\n                features1=[]\n                features2=[]\n#         return features1,features2\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T21:33:21.211277Z","iopub.execute_input":"2024-05-09T21:33:21.211897Z","iopub.status.idle":"2024-05-09T21:33:21.227272Z","shell.execute_reply.started":"2024-05-09T21:33:21.211863Z","shell.execute_reply":"2024-05-09T21:33:21.225966Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\ndef nansem(data, axis=None):\n    \"\"\"\n    Calculate the standard error of the mean (SEM) for arrays with NaN values.\n    \n    Parameters:\n    - data: Input array\n    - axis: Axis along which to compute SEM (default is None, which computes SEM for the flattened array)\n    \n    Returns:\n    - SEM: Standard error of the mean\n    \"\"\"\n    std = np.nanstd(data, axis=axis, ddof=1)  # Calculate standard deviation ignoring NaN values\n    n = np.sum(~np.isnan(data), axis=axis)  # Count non-NaN elements along the axis\n    SEM = std / np.sqrt(n)  # Calculate SEM\n    return SEM\n\n# Now you can use nansem instead of np.nansem in your code\n# layerwise_mi_figures(np.nanmean(thatcherIndex, axis=0), nansem(thatcherIndex, axis=0), saving_file_name, reference_mi, reference_name, dist_types, y_label)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T21:33:21.458796Z","iopub.execute_input":"2024-05-09T21:33:21.459214Z","iopub.status.idle":"2024-05-09T21:33:21.466544Z","shell.execute_reply.started":"2024-05-09T21:33:21.459184Z","shell.execute_reply":"2024-05-09T21:33:21.465592Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"# **LAYERWISE_MI_FIGURE**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Rectangle\nfrom matplotlib.lines import Line2D\n\n\ndef layerwise_mi_figures(mean_data, sem_data, file_name, reference_mi=None, reference_name=None, legend_name=None,\n                         y_label=None, shaded_region_name='Human perception', y_limits=None):\n    if y_limits is None:\n        y_limits = [-1, 1]\n\n    plt.figure(figsize=(7, 4))\n\n    # Drawing the human perception rectangle\n    plt.gca().add_patch(Rectangle((1, 0), 37, 1, facecolor=[0.8, 0.8, 0.8], edgecolor='none'))\n\n    # Naming the layers by drawing the bottom rectangles\n    layer_grouping = np.array([[1, 6.45], [6.55, 11.45], [11.55, 18.45], [18.55, 25.45], [25.55, 32.45], [32.55, 37]])\n    layer_colour = np.vstack([np.tile([0.8, 0.8, 0.8], (5, 1)), [0.5, 0.5, 0.5]])\n    box_width = 0.2 / (y_limits[1] - y_limits[0])\n\n    for ind, (start, end) in enumerate(layer_grouping):\n        plt.gca().add_patch(\n            Rectangle((start, y_limits[0]), end - start, box_width, facecolor=layer_colour[ind], edgecolor='none'))\n        plt.text(start + 0.4, y_limits[0] + box_width / 2, ['conv-1', 'conv-2', 'conv-3', 'conv-4', 'conv-5', 'fc'][ind], color='k', fontsize=6)\n\n    # Plotting the data\n    line_colour = plt.cm.get_cmap('tab10')\n    marker_size = 2\n    layer_ind = np.arange(1, 38)\n    # print(mean_data)\n    # print(np.array(mean_data).shape)\n    mean_data = np.array(mean_data)\n    for ind in range(mean_data.shape[0]):\n        if sem_data is not None and not np.all(np.isnan(sem_data)):\n            shadedErrorBar(layer_ind, mean_data[ind], sem_data[ind], lineprops=['-', {'markerfacecolor': line_colour(ind), 'color': line_colour(ind), 'linewidth': 0.5}], transparent=True, patchSaturation=0.3)\n        else:\n            plt.plot(layer_ind, mean_data[ind], '-', markerfacecolor=line_colour(ind), color=line_colour(ind), linewidth=0.5)\n\n        plt.plot(layer_ind[1:14:2], mean_data[ind, 1:14:2], 'o', markersize=marker_size,\n                 markeredgecolor=line_colour(ind))\n        plt.plot(layer_ind[2:15:2], mean_data[ind, 2:15:2], 'o', markersize=marker_size,\n                 markeredgecolor=line_colour(ind), markerfacecolor=line_colour(ind))\n        plt.plot(layer_ind[5:16:3], mean_data[ind, 5:16:3], 'd', markersize=marker_size,\n                 markeredgecolor=line_colour(ind), markerfacecolor=line_colour(ind))\n        plt.plot(layer_ind[32:], mean_data[ind, 32:], 's', markersize=marker_size, markeredgecolor=line_colour(ind))\n\n    # Visual search modulation index\n    if reference_mi is not None:\n        if isinstance(reference_mi, (list, np.ndarray)):\n            for i, mi in enumerate(reference_mi):\n                plt.plot([1, 37], [mi, mi], '--', color='k', linewidth=0.5)\n                plt.text(2, mi + 0.1, reference_name[i], fontsize=6)\n        else:\n            plt.plot([1, 37], [reference_mi, reference_mi], '--', color='k', linewidth=0.5)\n            plt.text(2, reference_mi + 0.1, reference_name, fontsize=6)\n\n    # Naming the shaded region\n    plt.text(3, 0.9, shaded_region_name, fontsize=6)\n\n    plt.xlim(0.5, 37.5)\n    plt.ylim(y_limits)\n    plt.xticks(range(1, 38))\n    plt.yticks(np.linspace(y_limits[0], y_limits[1], 5))\n\n    plt.xlabel('VGG-16 layers')\n    plt.ylabel(y_label)\n\n    if legend_name is not None:\n        handles, labels = plt.gca().get_legend_handles_labels()\n        plt.legend(handles, labels, fontsize=6, loc='best', bbox_to_anchor=(1, 1), frameon=False)\n\n    plt.tight_layout()\n  #  plt.savefig(file_name + '.pdf')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-09T21:33:21.848124Z","iopub.execute_input":"2024-05-09T21:33:21.848748Z","iopub.status.idle":"2024-05-09T21:33:21.873661Z","shell.execute_reply.started":"2024-05-09T21:33:21.848716Z","shell.execute_reply":"2024-05-09T21:33:21.872426Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"# **MAIN CODE**","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy.io\n\n\n# Main Code Directory location and SLASH of the OS\ndef get_expmainfolder_slash():\n    main_folder = '..'\n    SLASH = os.sep\n    return main_folder, SLASH\n\n# Adding Path\ndef add_paths(main_folder):\n    SLASH = os.sep\n    os.path.join(main_folder, 'dependencies', SLASH, 'matconvnet-1.0-beta24')\n    os.path.join(main_folder, 'dependencies', SLASH, 'models')\n    os.path.join(main_folder, 'dependencies', SLASH, 'lib')\n    run_path = os.path.join(main_folder, 'dependencies', SLASH, 'matconvnet-1.0-beta24', SLASH, 'matlab', SLASH, 'vl_setupnn')\n    return run_path\n\n# STIM\ndef preprocess_stim(stim):\n    S = 50\n    for i in range(len(stim)):\n        x = stim[i][0]\n#         print(x,x.shape)\n        stim[i][0] = x[S:x.shape[0]-S, :]\n    return stim\n\n# Networks\n# network_types = ['imagenet-vgg-verydeep-16', 'imagenet-matconvnet-vgg-verydeep-16.mat', 'imagenet-vgg-verydeep-16_randn.mat',\n#                 'imagenet-vgg-face', 'imagenet-caffe-alex', 'imagenet-googlenet-dag', 'imagenet-resnet-50-dag', 'imagenet-resnet-152-dag']\n# dagg_flags = [0, 0, 0, 0, 0, 0, 1, 1]\n# network_short_names = ['VGG-16', 'mat.VGG-16', 'VGG-16 randn', 'VGG-face', 'Alexnet', 'Goolgenet', 'ResNet 50', 'ResNet 152']\nnetwork_types = ['/kaggle/input/resnet50/other/2/1/imagenet-vgg-verydeep-16.mat']\ndagg_flags = [0]\nnetwork_short_names = ['VGG-face']\n\n\n\n# Effect Reference Level\nreference_mi = (4.89 - 2.92) / (4.89 + 2.92)  # Table-2, Bartlet and Searcy, 1993\nreference_name = 'Bartlet and Searcy, 1993'\nMI_across_layers = [None] * len(network_types)\n# Main Code\ndef main():\n#     main_folder, SLASH = get_expmainfolder_slash()\n#     run_path = add_paths(main_folder)\n\n    # Load Stimuli\n    stim_file_name = '/kaggle/input/tacherfaces/tatcherFaces.mat'\n    stim = scipy.io.loadmat(stim_file_name)['stim']\n    print('stim1',len(stim))\n    stim = preprocess_stim(stim)\n#     stim=stim[50:len(stim)-50]\n    print('stim2',len(stim))\n#     for a in stim:\n#         print(a[0].shape,a[0])\n#     print(np.array(stim.shape),stim)\n    \n#     \n    \n    time_taken = [None] * len(network_types)\n#     MI_across_layers = [None] * len(network_types)\n\n    for iter in range(len(network_types)):\n        print(f'\\n Network- {network_types[iter]} \\n')\n        print('\\n Extracting Features\\n')\n        print('No of images;',len(stim))\n        extract_features(stim, network_types[iter], dagg_flags[iter])\n#         nL = len(features[0]) - 1\n#         print('\\n Checking thatcherization\\n')\n# #         print(len(features),'feature')\n#         thatcherIndex = CheckThatcherEffect(features)\n#         print(thatcherIndex,'Thacjer effect')\n        MI_across_layers[iter] = thatcherIndex\n\n        dist_types = 'Euclidean'\n        y_label = 'Thatcher Index'\n#         saving_file_name = os.path.join('..', SLASH, 'results', SLASH, f'Exp01-TI,net = {network_short_names[iter]} metric = {dist_types}')\n        saving_file_name = f'results/{f\"Exp01-TI_net_{network_short_names[iter]}_metric_{dist_types}\"}'\n        print(saving_file_name)\n        # Effect Reference Level\n        thacherIndex=[]\n        thacherIndex.append(thatcherIndex1)\n        thacherIndex.append(thatcherIndex2)\n# if iter <= 3:  # Layer-wise plot for VGG-Network\n#             layerwise_mi_figures(np.nanmean(thatcherIndex, axis=0), nansem(thatcherIndex, axis=0), saving_file_name, reference_mi, reference_name, dist_types, y_label)\n#         else:  # Layer-wise plot for other networks\n#             layerwise_mi_nonVGGfigures(np.nanmean(thatcherIndex, axis=0), nansem(thatcherIndex, axis=0), saving_file_name, reference_mi, reference_name, dist_types, y_label)\n    \n#     print('Now Plot')\n#     sel_index = [0, 2, 3]\n#     N = len(sel_index)\n#     mean_data = np.zeros((N, 37))\n# #     print(mean_data.shape)\n#     sem_data = np.zeros((N, 37))\n#     for ind in range(N):\n#         print(len(MI_across_layers),MI_across_layers[0],'MIT Index')\n#         a=np.nanmean(MI_across_layers[sel_index[ind]], axis=0)\n#         print(a)\n#         mean_data[ind, :] = np.nanmean(MI_across_layers[sel_index[ind]], axis=0)\n#         sem_data[ind, :] = np.nansem(MI_across_layers[sel_index[ind]], axis=0)\n#     file_name = os.path.join('..', SLASH, 'results', SLASH, 'Exp01_mainfigure_VGG16_variants')\n#     layerwise_mi_figures(mean_data, sem_data, file_name, reference_mi, reference_name, [network_short_names[i] for i in sel_index], 'Thatcher Index')\n#     print('New result')\n#     sel_index = [0, 1]\n#     N = len(sel_index)\n#     mean_data = np.zeros((N, 37))\n#     sem_data = np.zeros((N, 37))\n#     for ind in range(N):\n#         mean_data[ind, :] = np.nanmean(MI_across_layers[sel_index[ind]], axis=0)\n#         sem_data[ind, :] = np.nansem(MI_across_layers[sel_index[ind]], axis=0)\n# #     file_name = os.path.join('..', SLASH, 'results', SLASH, 'Exp01_suppfigure_comparing VGG16 with matconvnet VGG16')\n#     layerwise_mi_figures(mean_data, sem_data, 'file_name', reference_mi, reference_name, [network_short_names[i] for i in sel_index], 'Thatcher Index')\n\nif __name__ == '__main__':\n    main()\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T21:39:50.203112Z","iopub.execute_input":"2024-05-09T21:39:50.203544Z","iopub.status.idle":"2024-05-09T21:44:54.808551Z","shell.execute_reply.started":"2024-05-09T21:39:50.203516Z","shell.execute_reply":"2024-05-09T21:44:54.807129Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"stim1 80\nstim2 80\n\n Network- /kaggle/input/resnet50/other/2/1/imagenet-vgg-verydeep-16.mat \n\n\n Extracting Features\n\nNo of images; 80\nImage: 0\nImage: 1\nImage: 2\nImage: 3\nCalculating CheckThatcherEffect of 4 images\nImage: 4\nImage: 5\nImage: 6\nImage: 7\nCalculating CheckThatcherEffect of 4 images\nImage: 8\nImage: 9\nImage: 10\nImage: 11\nCalculating CheckThatcherEffect of 4 images\nImage: 12\nImage: 13\nImage: 14\nImage: 15\nCalculating CheckThatcherEffect of 4 images\nImage: 16\nImage: 17\nImage: 18\nImage: 19\nCalculating CheckThatcherEffect of 4 images\nImage: 20\nImage: 21\nImage: 22\nImage: 23\nCalculating CheckThatcherEffect of 4 images\nImage: 24\nImage: 25\nImage: 26\nImage: 27\nCalculating CheckThatcherEffect of 4 images\nImage: 28\nImage: 29\nImage: 30\nImage: 31\nCalculating CheckThatcherEffect of 4 images\nImage: 32\nImage: 33\nImage: 34\nImage: 35\nCalculating CheckThatcherEffect of 4 images\nImage: 36\nImage: 37\nImage: 38\nImage: 39\nCalculating CheckThatcherEffect of 4 images\nImage: 40\nImage: 41\nImage: 42\nImage: 43\nCalculating CheckThatcherEffect of 4 images\nImage: 44\nImage: 45\nImage: 46\nImage: 47\nCalculating CheckThatcherEffect of 4 images\nImage: 48\nImage: 49\nImage: 50\nImage: 51\nCalculating CheckThatcherEffect of 4 images\nImage: 52\nImage: 53\nImage: 54\nImage: 55\nCalculating CheckThatcherEffect of 4 images\nImage: 56\nImage: 57\nImage: 58\nImage: 59\nCalculating CheckThatcherEffect of 4 images\nImage: 60\nImage: 61\nImage: 62\nImage: 63\nCalculating CheckThatcherEffect of 4 images\nImage: 64\nImage: 65\nImage: 66\nImage: 67\nCalculating CheckThatcherEffect of 4 images\nImage: 68\nImage: 69\nImage: 70\nImage: 71\nCalculating CheckThatcherEffect of 4 images\nImage: 72\nImage: 73\nImage: 74\nImage: 75\nCalculating CheckThatcherEffect of 4 images\nImage: 76\nImage: 77\nImage: 78\nImage: 79\nCalculating CheckThatcherEffect of 4 images\nresults/Exp01-TI_net_VGG-face_metric_Euclidean\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reference_mi = (4.89 - 2.92) / (4.89 + 2.92)  # Table-2, Bartlet and Searcy, 1993\nreference_name = 'Bartlet and Searcy, 1993'\ndist_types = 'Euclidean'\ny_label = 'Thatcher Index'\nlayerwise_mi_figures(nanmean(thatcherIndex), [], 'saving_file_name', reference_mi, reference_name, dist_types, y_label)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T21:28:47.520131Z","iopub.execute_input":"2024-05-09T21:28:47.520531Z","iopub.status.idle":"2024-05-09T21:28:48.121988Z","shell.execute_reply.started":"2024-05-09T21:28:47.520501Z","shell.execute_reply":"2024-05-09T21:28:48.120824Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_32/1456367342.py:28: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n  line_colour = plt.cm.get_cmap('tab10')\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 700x400 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"# **AGE PREDICTION**","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}